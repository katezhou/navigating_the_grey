{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72259d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from transformers import GPT2Tokenizer\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32da60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset():\n",
    "\n",
    "    def __init__(self, name, name_pretty, sample_questions_files):\n",
    "        self.name = name\n",
    "        self.name_pretty = name_pretty\n",
    "        self.sample_questions = pd.DataFrame()\n",
    "\n",
    "        for sample_questions_file in sample_questions_files: \n",
    "            self.sample_questions = pd.concat([self.sample_questions, pd.read_csv(sample_questions_file)])\n",
    "        self.sample_questions = self.sample_questions.drop_duplicates()\n",
    "        if name == 'triviaqa':\n",
    "            self.sample_questions = self.sample_questions[['Question_example', 'Answer.MatchedWikiEntityName_example', 'Question', 'Answer.Aliases']]\n",
    "            \n",
    "        elif name == 'countryqa':\n",
    "            self.sample_questions = self.sample_questions[['name_example', 'capital_example', 'name', 'capital']]\n",
    "        else:\n",
    "            self.sample_questions = self.sample_questions[['question_example', 'answer_example', 'question', 'answer']]\n",
    "        \n",
    "        if (self.name == 'jeopardy'):\n",
    "            self.sample_questions['question_example'] = self.sample_questions['question_example'].apply(lambda x: x.replace(\"<br />\", \" \"))\n",
    "            self.sample_questions['question'] = self.sample_questions['question'].apply(lambda x: x.replace(\"<br />\", \" \"))\n",
    "\n",
    "        self.sample_questions.columns = ['question_example', 'answer_example', 'question', 'answer']\n",
    "        \n",
    "        if name == 'boolqa':\n",
    "            self.sample_questions['answer'] =  self.sample_questions['answer'].astype(str)\n",
    "            self.sample_questions['answer_example'] =  self.sample_questions['answer_example'].astype(str)\n",
    "        self.answer_set = set()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ca1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_one_token_responses(df, answer_column_name):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    #tokenize all words using GPT2's tokenizer\n",
    "    df['tokens'] = df[answer_column_name].apply(lambda x: len(tokenizer(\" \" + str(x))['input_ids']))\n",
    "    df = df[df['tokens']==1]\n",
    "    #length of single token answer\n",
    "    print(\"Total number of one token answer examples:\", len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f348b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer_sets():\n",
    "    cities_data = pd.read_csv(folder_path + \"worldcities.csv\")\n",
    "    cities_data = cities_data[cities_data['population'] > 100000]\n",
    "    cities = set([x.lower() for x in cities_data['city']])\n",
    "    cities = cities.union(set([x.lower() for x in cities_data['country']]))\n",
    "\n",
    "    cities_data_pop_map = {}\n",
    "    for n, row in cities_data.iterrows():\n",
    "        cities_data_pop_map[row['city'].lower()] = row['population']\n",
    "    countryqa.answer_set = cities\n",
    "    print(len(cities))\n",
    "\n",
    "    trivia_data = pd.read_csv(folder_path + \"triviaqa/data/sample_questions_single_token_answers.csv\")\n",
    "    trivia_answers = set()\n",
    "    for n, row in trivia_data.iterrows():\n",
    "        temp = [x.strip(\"\\'\") for x in row['Answer.Aliases'].lower().strip('][').split(\"', \")]\n",
    "        for x in temp:\n",
    "            trivia_answers.add(x)\n",
    "    triviaqa.answer_set = trivia_answers       \n",
    "    print(len(trivia_answers))\n",
    "    \n",
    "    naturalqa_data = pd.read_csv(folder_path + \"naturalqa/data/sample_questions_single_token_answers.csv\")\n",
    "    naturalqa_answers = set()\n",
    "    for n, row in naturalqa_data.iterrows():\n",
    "        temp = [x.strip(\"\\'\") for x in row['answer'].lower().strip('][').split(\"', \")]\n",
    "        for x in temp:\n",
    "            naturalqa_answers.add(x)\n",
    "    naturalqa.answer_set = naturalqa_answers\n",
    "    print(len(naturalqa_answers))\n",
    "    \n",
    "    jeopardy_data = pd.read_csv(folder_path + \"jeopardy/data/sample_questions_single_token_answers.csv\")\n",
    "    jeopardy_answers = set()\n",
    "    jeopardy_data = jeopardy_data.fillna(\"nan\")\n",
    "    for n, row in jeopardy_data.iterrows():\n",
    "        temp = [x.strip(\"\\'\") for x in row['answer'].lower().strip('][').split(\"', \")]\n",
    "        for x in temp:\n",
    "            jeopardy_answers.add(x)\n",
    "    jeopardy.answer_set = jeopardy_answers\n",
    "    print(len(jeopardy_answers))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b36aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_on_cities_helper(predictions, logprobs, answer_set):\n",
    "    total_probability = 0\n",
    "    predictions = [x.strip(\"\\'\").strip(\" \") for x in predictions.lower().strip('][').split(\"', \")]\n",
    "    logprobs = [float(x.strip(\"\\'\")) for x in logprobs.lower().strip('][').split(\"', \")]\n",
    "    \n",
    "    unique_predictions = set()\n",
    "    for prediction, logprob in zip(predictions, logprobs):\n",
    "        if prediction in answer_set:\n",
    "            total_probability += np.e**logprob\n",
    "            unique_predictions.add(prediction)\n",
    "    return total_probability, unique_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c2ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_on_cities(queried, answer_set):\n",
    "    prob_on_answer_set = []\n",
    "    unique_predictions_results = []\n",
    "    for n, row in queried.iterrows():\n",
    "        answer_index = 'topk_predictions_answer_' + str(int(row['best_token_index']))\n",
    "        logprob_index = 'topk_predictions_log_prob_answer_' + str(int(row['best_token_index']))\n",
    "\n",
    "        probability, unique_predictions = calculate_probability_on_cities_helper(row[answer_index], row[logprob_index], answer_set)\n",
    "        prob_on_answer_set.append(probability)\n",
    "        unique_predictions_results.append(unique_predictions)\n",
    "        \n",
    "    queried['prob_on_answer_set'] = prob_on_answer_set\n",
    "    queried['unique_predictions_names'] = unique_predictions_results\n",
    "    return queried\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a0f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_prompts(current_df, name, MAX_QUESTIONS=200):\n",
    "    prompts_to_use = pd.DataFrame()\n",
    "    for n, row in current_df.sample_questions[:].iterrows():\n",
    "        question = row['question']\n",
    "\n",
    "        answer = [x.strip(\"\\'\") for x in row['answer'].lower().strip('][').split(', ')]\n",
    "        if current_df.name == 'triviaqa' or current_df.name == 'countryqa':\n",
    "            prompt = \"Q: \" + question + \"\\nA:\" + name\n",
    "        else:\n",
    "            prompt = \"Q: \" + question + \" A:\" + name\n",
    "        \n",
    "        prompts_to_use = pd.concat([prompts_to_use, pd.DataFrame([[prompt, \n",
    "                                                                   question, \n",
    "                                                                   answer]])])\n",
    "    prompts_to_use.columns = ['prompt', \n",
    "                           'question', \n",
    "                           'answer']\n",
    "    return prompts_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe8c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_unique_predictions(queried, answer_set):\n",
    "    unique_predictions_df = pd.DataFrame()\n",
    "    for name, group in queried.groupby(\"name\"):\n",
    "        total_predictions = set()\n",
    "        for n, row in group.iterrows():\n",
    "            predictions = row['unique_predictions_names']\n",
    "            for prediction in predictions:\n",
    "                if (prediction in answer_set):\n",
    "                    total_predictions.add(prediction)\n",
    "                   \n",
    "        unique_predictions_df = pd.concat([unique_predictions_df, pd.DataFrame([[name, len(total_predictions)]])])\n",
    "    \n",
    "    unique_predictions_df.columns = ['name', 'unique_predictions']\n",
    "    return unique_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c29e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_checker(row, topk):\n",
    "    answers = [x.strip(\"\\'\") for x in row['answers'].lower().strip('][').split(\"', \")]\n",
    "    \n",
    "    #what to go through all the predictions at each index and look at topk response\n",
    "    for n in range(0, 9):\n",
    "        predictions = [x.strip(\"\\'\").strip() for x in str(row['topk_predictions_answer_' + str(n)]).lower().strip('][').split(\"', \")]\n",
    "        for answer in answers:\n",
    "            #see if any answer matches any of the predictions\n",
    "            if answer in predictions[:topk]:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a10a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefixes():\n",
    "    prefix_df = pd.read_csv(folder_path + \"uncertainty_template_meta.csv\")\n",
    "    prefix_df['name'] = prefix_df['name'].apply(lambda x: \" \" + x)\n",
    "    prefixes = list(prefix_df['name'].values) + [\"\"]\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba4d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts_to_use(prefixes, current_df):\n",
    "    prompts_to_use = set()\n",
    "    for prefix in prefixes:\n",
    "        for x in building_prompts(current_df, prefix)['prompt'].values:\n",
    "            prompts_to_use.add(x)\n",
    "    return prompts_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17431b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name(x):\n",
    "    if x == 'unprompted':\n",
    "        return \"Standard Method\"\n",
    "    else:\n",
    "        return \" \" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1433b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_predictions_by_row(row, current_df):\n",
    "    predictions_set = set()\n",
    "    for n in range(0, 9):\n",
    "        predictions = [x.strip(\"\\'\").replace(\" \", \"\") for x in str(row['topk_predictions_answer_' + str(n)]).lower().strip('][').split(\"', \")]\n",
    "        \n",
    "        for prediction in predictions:\n",
    "            if (prediction in current_df.answer_set):\n",
    "                predictions_set.add(prediction)\n",
    "    return len(predictions_set)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c2871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_string_gpt4(text):\n",
    "    predictions = [x.strip(\"\\'\").replace(\" \", \"\") for x in text.lower().strip('][').split(\"', \")]\n",
    "    predictions = \"\".join(predictions)\n",
    "    return predictions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6e5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(current_df, MODEL_NAME, NUM_COMPLETIONS, MAX_TOKENS, TEMPERATURE, TOP_K_PER_TOKEN, STOP_SEQUENCES):\n",
    "    if (current_df.name == 'jeopardy'):\n",
    "        experiment_name = \"gricean_experiment_qa_cleaned\"\n",
    "    else:\n",
    "        experiment_name = \"gricean_experiment_qa\"\n",
    "\n",
    "    path = current_df.name + '/results/'\n",
    "    output_file = folder_path + path + str(MAX_TOKENS) + \"_\" + str(TEMPERATURE)[-1:] + \"_\" + MODEL_NAME.replace(\"/\", \"_\") + \"_\" + experiment_name + '.csv'\n",
    "        \n",
    "    prefixes = get_prefixes()\n",
    "    prompts_to_use = get_prompts_to_use(prefixes, current_df)\n",
    "\n",
    "    queried = pd.read_csv(output_file, header=None).drop_duplicates()\n",
    "    queried.columns = ['prompt', \n",
    "                       'question', \n",
    "                       'answers',\n",
    "                       'best_gold_answer_logprob_answer',\n",
    "                       'best_token_index',\n",
    "                       'text',\n",
    "                       'name'] + ['topk_predictions_answer_' + str(x) for x in range(0, 10)] + ['topk_predictions_log_prob_answer_' + str(x) for x in range(0, 10)]\n",
    "\n",
    "    queried['name'] = queried['name'].fillna(\"unprompted\")\n",
    "    queried = queried[queried['name'] != \" I don't think it's\"]\n",
    "    queried = queried[queried['name'] != \" I seriously doubt it's\"]\n",
    "    \n",
    "    #HACK FOR GPT4\n",
    "#     queried['topk_predictions_answer_0'] = queried['text'].apply(lambda y: transform_string_gpt4(y))\n",
    "\n",
    "\n",
    "    queried = queried[queried['prompt'].isin(prompts_to_use)]\n",
    "#     print(\"number of results\", len(queried)) \n",
    "    \n",
    "    queried['correct_top_1'] = queried.apply(lambda x: answer_checker(x, 1),axis=1)\n",
    "    queried['correct_top_10'] = queried.apply(lambda x: answer_checker(x, 10),axis=1)\n",
    "    queried['unique_predictions'] = queried.apply(lambda x: unique_predictions_by_row(x, current_df), axis=1)\n",
    "    queried['ratio'] = queried['correct_top_1']/ queried['best_gold_answer_logprob_answer']\n",
    "\n",
    "    current_df.raw_results = queried\n",
    "\n",
    "#     keeping only easy questions\n",
    "    temp = queried[queried['name']=='unprompted']\n",
    "    easy_questions = set(temp.sort_values(by='best_gold_answer_logprob_answer').tail(25)['question'].values)\n",
    "\n",
    "    queried = queried.groupby(\"name\").mean().reset_index()\n",
    "#     queried = queried.set_index(\"name\").join(unique_predictions_map.set_index('name'), how='outer').reset_index()\n",
    "    queried['ratio'] = queried['correct_top_1']/ queried['best_gold_answer_logprob_answer']\n",
    "\n",
    "#     display(queried)\n",
    "    current_df.results = queried\n",
    "    current_df.easy_questions = easy_questions\n",
    "    return current_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3da699",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Read in Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "280674ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_confidence(queried, y_variable, x_variables, category):\n",
    "    meta = pd.read_csv(folder_path + \"uncertainty_template_meta.csv\")\n",
    "    meta = meta[meta['name'] != \"I seriously doubt it's\"]\n",
    "    meta = meta[meta['name'] != \"I don't think it's\"]\n",
    "\n",
    "    meta['name'] = meta['name'].apply(lambda x: transform_name(x))\n",
    "#     meta = meta[meta['factive_verb'] != 'factive_verb']\n",
    "    bootstrap = queried.set_index(\"name\").join(meta.set_index(\"name\")).reset_index()\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    for x_variable in x_variables:\n",
    "        temp = []\n",
    "        for x in range(0, 500):\n",
    "            temp.append(list(bootstrap[bootstrap[category]==x_variable].sample(frac=1, replace=True)[[y_variable]].mean()))\n",
    "\n",
    "        avgs = np.mean(np.array(temp), axis=0)\n",
    "        q2 = np.quantile(np.array(temp), axis=0, q=0.025)\n",
    "        q97 = np.quantile(np.array(temp), axis=0, q=0.975)\n",
    "        stds = np.std(np.array(temp), axis=0)\n",
    "    \n",
    "        results = pd.concat([results, pd.DataFrame([[category] + [x_variable] + list(avgs) + list(q2) + list(q97) + list(stds)])])\n",
    "        print(\"Bootstrap results percentile .025\", round(q2[0], 5), \"percentile .975\", round(q97[0], 5))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf92a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df, y_variable, x_variables, x_variables_pretty, y_label, title, category, bootstrap_results):\n",
    "    print(df['dataset'].values)\n",
    "    N = len(set(df['dataset'].values))\n",
    "    ind = np.arange(N) \n",
    "    width = 0.25\n",
    "\n",
    "    df = df.sort_values(by='dataset')\n",
    "    \n",
    "    bootstrap_results = bootstrap_results.sort_values(by='dataset')\n",
    "    \n",
    "#     xvals = df[df[category] == x_variables[0]][y_variable].values\n",
    "    \n",
    "    boostrap_temp = (bootstrap_results[bootstrap_results[1]==x_variables[0]][5].values)*1.96\n",
    "\n",
    "    std1 = bootstrap_results[bootstrap_results[1]==x_variables[0]][5].values\n",
    "    avg1 = bootstrap_results[bootstrap_results[1]==x_variables[0]][2].values\n",
    "    bar1 = plt.bar(ind, avg1, width, color = '#1f77b4', yerr=boostrap_temp, capsize=7)\n",
    "\n",
    "    \n",
    "#     yvals = df[df[category] == x_variables[1]][y_variable].values\n",
    "    boostrap_temp = (bootstrap_results[bootstrap_results[1]==x_variables[1]][5].values)*1.96\n",
    "    std2 = bootstrap_results[bootstrap_results[1]==x_variables[1]][5].values\n",
    "    avg2 = bootstrap_results[bootstrap_results[1]==x_variables[1]][2].values\n",
    "    bar2 = plt.bar(ind+width, avg2, width, color='#ff7f03', yerr=boostrap_temp, capsize=7)\n",
    "\n",
    "    avg3 = None\n",
    "    std3 = None\n",
    "    if (len(x_variables)==3):\n",
    "#         zvals = df[df[category] == x_variables[2]][y_variable].values\n",
    "        boostrap_temp = (bootstrap_results[bootstrap_results[1]==x_variables[2]][5].values)*1.96\n",
    "        std3 = bootstrap_results[bootstrap_results[1]==x_variables[2]][5].values\n",
    "        avg3 = bootstrap_results[bootstrap_results[1]==x_variables[2]][2].values\n",
    "        bar3 = plt.bar(ind+width*2, avg3, width, color = '#2ca02c', yerr=boostrap_temp, capsize=7)\n",
    "\n",
    "    plt.xlabel(\"Datasets\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xticks(ind+width,sorted(set(df['dataset'].values)))\n",
    "    if (len(x_variables)==3):\n",
    "        plt.legend( (bar1, bar2, bar3), x_variables_pretty)\n",
    "    else:\n",
    "        plt.legend( (bar1, bar2), x_variables_pretty)\n",
    "\n",
    "#     plt.savefig(\"figures/correct_top_1_by_\" + category + \".pdf\", dpi=200, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    \n",
    "    print(x_variable, y_variable, avg1, std1, avg2, std2, avg3, std3)\n",
    "    return avg1, std1, avg2, std2, avg3, std3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c8c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_significance(avg1, std1, avg2, std2, avg3, std3):\n",
    "    for x in range(0, 4):\n",
    "        a = (avg2[x] - avg1[x]) + 2.05 * math.sqrt(std1[x]**2 + std2[x]**2)\n",
    "        b = (avg2[x] - avg1[x]) - 2.05 * math.sqrt(std1[x]**2 + std2[x]**2)\n",
    "        print(a, b)\n",
    "        if (a > 0 and b > 0) or (a < 0 and b < 0):\n",
    "            print(\"Significant!\")\n",
    "        else:\n",
    "            print(\"Not Significant!\")\n",
    "\n",
    "    print(\"----\")\n",
    "\n",
    "    if avg3 is not None:\n",
    "        for x in range(0, 4):\n",
    "            a = (avg3[x] - avg1[x]) + 2.05 * math.sqrt(std1[x]**2 + std3[x]**2)\n",
    "            b = (avg3[x] - avg1[x]) - 2.05 * math.sqrt(std1[x]**2 + std3[x]**2)\n",
    "            print(a, b)\n",
    "            if (a > 0 and b > 0) or (a < 0 and b < 0):\n",
    "                print(\"Significant!\")\n",
    "            else:\n",
    "                print(\"Not Significant!\")\n",
    "                \n",
    "    print(\"----\")  \n",
    "    \n",
    "    if avg3 is not None:\n",
    "        for x in range(0, 4):\n",
    "            a = (avg3[x] - avg2[x]) + 2.05 * math.sqrt(std2[x]**2 + std3[x]**2)\n",
    "            b = (avg3[x] - avg2[x]) - 2.05 * math.sqrt(std2[x]**2 + std3[x]**2)\n",
    "            print(a, b)\n",
    "            if (a > 0 and b > 0) or (a < 0 and b < 0):\n",
    "                print(\"Significant!\")\n",
    "            else:\n",
    "                print(\"Not Significant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc55fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_checker(row, topk):\n",
    "    answers = [x.strip(\"\\'\") for x in row['answers'].lower().strip('][').split(\"', \")]\n",
    "    \n",
    "    #what to go through all the predictions at each index and look at topk response\n",
    "    for n in range(0, 9):\n",
    "        predictions = [x.strip(\"\\'\").replace(\" \", \"\") for x in str(row['topk_predictions_answer_' + str(n)]).lower().strip('][').split(\"', \")]\n",
    "        for answer in answers:\n",
    "            #see if any answer matches any of the predictions\n",
    "            if answer in predictions[:topk]:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ece0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(df, y_variable):\n",
    "    meta = pd.read_csv(\"uncertainty_template_meta.csv\")\n",
    "    meta = meta[meta['name'] != \"I seriously doubt it's\"]\n",
    "    meta = meta[meta['name'] != \"I don't think it's\"]\n",
    "\n",
    "    meta['name'] = meta['name'].apply(lambda x: transform_name(x))\n",
    "    df = df.set_index(\"name\").join(meta.set_index(\"name\")).reset_index()\n",
    "    \n",
    "    stds = {}\n",
    "    for n, group in df.groupby(['booster', 'shield']):\n",
    "        \n",
    "        temp = []\n",
    "        for x in range(0, 500):\n",
    "            temp.append(df.sample(frac=1, replace=True)[[y_variable]].mean()[0])\n",
    "        \n",
    "        stds[n] = np.std(np.array(temp))\n",
    "    print(\"stds\", stds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0d8f0",
   "metadata": {},
   "source": [
    "# Running Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55391e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COMPLETIONS = 1\n",
    "MAX_TOKENS = 10\n",
    "TEMPERATURE = 1\n",
    "MODEL_NAME = \"openai/davinci\"\n",
    "TOP_K_PER_TOKEN = 50\n",
    "ECHO_PROMPT = False\n",
    "\n",
    "STOP_SEQUENCES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e6fee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(folder_path, dataset_name, name_pretty):\n",
    "    if dataset_name == 'countryqa':\n",
    "        df = dataset('countryqa', name_pretty, [folder_path + \"countryqa/data/all_questions.csv\"])\n",
    "        df.sample_questions = filter_one_token_responses(df.sample_questions, 'answer')\n",
    "    else:\n",
    "        df = dataset(dataset_name, name_pretty, [folder_path + dataset_name + \"/data/sample_questions_single_token_answers_50.csv\",\n",
    "                                       folder_path + dataset_name + \"/data/sample_questions_single_token_answers_50_2.csv\",\n",
    "                                      folder_path +  dataset_name + \"/data/sample_questions_single_token_answers_100.csv\"])\n",
    "    print(\"number of questions read in\", len(df.sample_questions))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02762456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of questions read in 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dc466f710f401b8a36554ee4192b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d474e9a1700480ca0e72281394d8770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e94e2f57040ef8571f0035f525462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of one token answer examples: 53\n",
      "number of questions read in 53\n",
      "number of questions read in 220\n",
      "number of questions read in 220\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/u/scr/katezhou/Uncertainty/interpretability/'\n",
    "\n",
    "triviaqa = get_datasets(folder_path, 'triviaqa', 'TriviaQA')\n",
    "countrqa = get_datasets(folder_path, 'countryqa', 'CountryQA')\n",
    "naturalqa = get_datasets(folder_path, 'naturalqa', 'NaturalQA')\n",
    "jeopardy = get_datasets(folder_path, 'jeopardy', 'Jeopardy')\n",
    "\n",
    "datasets = [triviaqa, countrqa, naturalqa, jeopardy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae0afbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name openai/ada\n",
      "10200\n",
      "2703\n",
      "10200\n",
      "10200\n",
      "Model name openai/babbage\n",
      "10200\n",
      "2703\n",
      "10200\n",
      "10200\n",
      "Model name openai/curie\n",
      "10200\n",
      "2703\n",
      "10200\n",
      "10200\n",
      "Model name openai/davinci\n",
      "10200\n",
      "2703\n",
      "10200\n",
      "10200\n",
      "Model name openai/text-davinci-003\n",
      "10200\n",
      "2703\n",
      "10200\n",
      "10200\n"
     ]
    }
   ],
   "source": [
    "for MODEL_NAME in [\"openai/ada\", \"openai/babbage\", \"openai/curie\", \"openai/davinci\",  \"openai/text-davinci-003\"]:\n",
    "\n",
    "    print(\"Model name\", MODEL_NAME)\n",
    "    \n",
    "    for df in datasets:\n",
    "        results = get_results(df, MODEL_NAME, NUM_COMPLETIONS, MAX_TOKENS, TEMPERATURE, TOP_K_PER_TOKEN, STOP_SEQUENCES)\n",
    "        print(len(results.raw_results))\n",
    "#         display(df.raw_results.groupby(\"name\").count())\n",
    "#         display(df.raw_results.groupby(\"name\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc96c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa290318",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(folder_path + \"uncertainty_template_meta.csv\")\n",
    "meta = meta[meta['name'] != \"I seriously doubt it's\"]\n",
    "meta = meta[meta['name'] != \"I don't think it's\"]\n",
    "meta['name'] = meta['name'].apply(lambda x: transform_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5274518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable_map = {}\n",
    "x_variable_map['shield'] = ['plausibility', 'None']\n",
    "x_variable_map['ppn'] = ['ppn', 'no_ppn']\n",
    "x_variable_map['evi_markers'] = ['evidential_marker', 'no_evidential_marker']\n",
    "x_variable_map['factive_verb'] = ['factive_verb', 'no_factive_verb']\n",
    "x_variable_map['authority'] = ['authority', 'no_authority']\n",
    "x_variable_map['booster'] = ['booster', 'hedge']\n",
    "\n",
    "x_variable_map_pretty = {}\n",
    "x_variable_map_pretty['shield'] = ['Plausibility', 'Not Plausibility' ]\n",
    "x_variable_map_pretty['ppn'] = ['Personal Pronoun', 'Not Personal Pronoun']\n",
    "x_variable_map_pretty['evi_markers'] = ['Evidential', 'Not Evidential']\n",
    "x_variable_map_pretty['factive_verb'] = ['Factive', 'Not Factive']\n",
    "x_variable_map_pretty['authority'] = ['Source', 'No Source']\n",
    "x_variable_map_pretty['booster'] = ['Strengthener', 'Weakener']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "822ce870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def templates_meta_data():\n",
    "    meta = pd.read_csv(\"uncertainty_template_meta.csv\")\n",
    "    meta = meta[meta['name'] != \"I seriously doubt it's\"]\n",
    "    meta = meta[meta['name'] != \"I don't think it's\"]\n",
    "    meta['name'] = meta['name'].apply(lambda x: transform_name(x))\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd00b8",
   "metadata": {},
   "source": [
    "# All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7de9e67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name openai/ada\n",
      "Model name openai/babbage\n",
      "Model name openai/curie\n",
      "Model name openai/davinci\n",
      "Model name openai/text-davinci-003\n"
     ]
    }
   ],
   "source": [
    "all_raw_results = pd.DataFrame()\n",
    "all_combined_results = pd.DataFrame()\n",
    "\n",
    "for MODEL_NAME in [\"openai/ada\", \"openai/babbage\", \"openai/curie\", \"openai/davinci\", \"openai/text-davinci-003\"]:\n",
    "    print(\"Model name\", MODEL_NAME)    \n",
    "    features = ['correct_top_1']\n",
    "    for current_df in datasets[:]:\n",
    "        current_df = get_results(current_df, MODEL_NAME, NUM_COMPLETIONS, MAX_TOKENS, TEMPERATURE, TOP_K_PER_TOKEN, STOP_SEQUENCES)\n",
    "        all_raw_results = pd.concat([all_raw_results, current_df.raw_results])\n",
    "        all_combined_results = pd.concat([all_combined_results, current_df.results])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b112a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'non_gpt4_results' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "non_gpt4_results = all_raw_results\n",
    "%store non_gpt4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d31d9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name openai/ada\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster          0.091\n",
       "1    hedge          0.079\n",
       "2     none          0.092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.05942 percentile .975 0.06794\n",
      "Bootstrap results percentile .025 0.05715 percentile .975 0.0635\n",
      "0.06363791049855369 0.06021834708294225\n",
      "booster Ttest_indResult(statistic=1.2276438214444194, pvalue=0.21958973577053745)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker          0.087\n",
       "1  no_evidential_marker          0.080"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.06165 percentile .975 0.06917\n",
      "Bootstrap results percentile .025 0.05343 percentile .975 0.06129\n",
      "0.06522602234700244 0.05726080298288834\n",
      "evi_markers Ttest_indResult(statistic=2.9847079862360255, pvalue=0.002840593242969548)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb          0.078\n",
       "1  no_factive_verb          0.085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.05095 percentile .975 0.06153\n",
      "Bootstrap results percentile .025 0.06006 percentile .975 0.06609\n",
      "0.05624390923012669 0.06306200180625908\n",
      "factive_verb Ttest_indResult(statistic=-2.1233451190087314, pvalue=0.033732442544149484)\n",
      "-----------\n",
      "Model name openai/babbage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster          0.257\n",
       "1    hedge          0.272\n",
       "2     none          0.284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.1371 percentile .975 0.14966\n",
      "Bootstrap results percentile .025 0.14592 percentile .975 0.15593\n",
      "0.14318529862174578 0.15091636615126217\n",
      "booster Ttest_indResult(statistic=-1.877077606408582, pvalue=0.06051654989273332)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker          0.281\n",
       "1  no_evidential_marker          0.250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.15449 percentile .975 0.16483\n",
      "Bootstrap results percentile .025 0.12933 percentile .975 0.13996\n",
      "0.15954852248879814 0.13482921632598707\n",
      "evi_markers Ttest_indResult(statistic=6.269541587506201, pvalue=3.6663692824981426e-10)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb          0.237\n",
       "1  no_factive_verb          0.276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.12578 percentile .975 0.14076\n",
      "Bootstrap results percentile .025 0.14815 percentile .975 0.15656\n",
      "0.1326743700403731 0.15255035928849098\n",
      "factive_verb Ttest_indResult(statistic=-4.188576838572113, pvalue=2.814455514600025e-05)\n",
      "-----------\n",
      "Model name openai/curie\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster          0.313\n",
       "1    hedge          0.333\n",
       "2     none          0.340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.19414 percentile .975 0.20806\n",
      "Bootstrap results percentile .025 0.21358 percentile .975 0.22423\n",
      "0.20137825421133232 0.21923627920762734\n",
      "booster Ttest_indResult(statistic=-3.7640511127723486, pvalue=0.00016748128704693636)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker          0.347\n",
       "1  no_evidential_marker          0.301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.22259 percentile .975 0.23521\n",
      "Bootstrap results percentile .025 0.18843 percentile .975 0.20161\n",
      "0.22874482445692246 0.19455356548372063\n",
      "evi_markers Ttest_indResult(statistic=7.526723443398362, pvalue=5.3368283677292866e-14)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb          0.293\n",
       "1  no_factive_verb          0.336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.1784 percentile .975 0.19567\n",
      "Bootstrap results percentile .025 0.21579 percentile .975 0.22559\n",
      "0.18710845050814423 0.22032434130443318\n",
      "factive_verb Ttest_indResult(statistic=-6.075590838468885, pvalue=1.2489644719999524e-09)\n",
      "-----------\n",
      "Model name openai/davinci\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster          0.392\n",
       "1    hedge          0.468\n",
       "2     none          0.515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.29684 percentile .975 0.31338\n",
      "Bootstrap results percentile .025 0.35405 percentile .975 0.36685\n",
      "0.3052577845839714 0.3601738872696735\n",
      "booster Ttest_indResult(statistic=-10.012198463202768, pvalue=1.459328899620689e-23)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker          0.449\n",
       "1  no_evidential_marker          0.433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.34037 percentile .975 0.35418\n",
      "Bootstrap results percentile .025 0.32768 percentile .975 0.3431\n",
      "0.34683228404514777 0.3350422797789467\n",
      "evi_markers Ttest_indResult(statistic=2.239267902414427, pvalue=0.025145196374582065)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb          0.347\n",
       "1  no_factive_verb          0.468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.25533 percentile .975 0.27531\n",
      "Bootstrap results percentile .025 0.35671 percentile .975 0.36858\n",
      "0.2653487400807462 0.36286174264734755\n",
      "factive_verb Ttest_indResult(statistic=-15.448477430500004, pvalue=1.1966119540623695e-53)\n",
      "-----------\n",
      "Model name openai/text-davinci-003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster          0.589\n",
       "1    hedge          0.642\n",
       "2     none          0.615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.50485 percentile .975 0.52289\n",
      "Bootstrap results percentile .025 0.56106 percentile .975 0.57437\n",
      "0.5134422324315127 0.5677518154423752\n",
      "booster Ttest_indResult(statistic=-9.42245541918447, pvalue=4.692471530369443e-21)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker          0.640\n",
       "1  no_evidential_marker          0.601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.55964 percentile .975 0.574\n",
      "Bootstrap results percentile .025 0.51733 percentile .975 0.53247\n",
      "0.5669559298962056 0.5246687529129769\n",
      "evi_markers Ttest_indResult(statistic=7.657754298324855, pvalue=1.944279675022043e-14)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb          0.555\n",
       "1  no_factive_verb          0.641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.46575 percentile .975 0.48949\n",
      "Bootstrap results percentile .025 0.5618 percentile .975 0.57363\n",
      "0.47751635806765974 0.5672438842423528\n",
      "factive_verb Ttest_indResult(statistic=-13.53087607275304, pvalue=1.33114644448199e-41)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "pretty_booster = pd.DataFrame()\n",
    "pretty_evi = pd.DataFrame()\n",
    "pretty_factive = pd.DataFrame()\n",
    "        \n",
    "for MODEL_NAME in [\"openai/ada\", \"openai/babbage\", \"openai/curie\", \"openai/davinci\", \"openai/text-davinci-003\"]:\n",
    "    print(\"Model name\", MODEL_NAME)\n",
    "\n",
    "    all_raw_results = pd.DataFrame()\n",
    "    all_combined_results = pd.DataFrame()\n",
    "    features = ['correct_top_1']\n",
    "    for current_df in datasets[:]:\n",
    "        current_df = get_results(current_df, MODEL_NAME, NUM_COMPLETIONS, MAX_TOKENS, TEMPERATURE, TOP_K_PER_TOKEN, STOP_SEQUENCES)\n",
    "        all_raw_results = pd.concat([all_raw_results, current_df.raw_results])\n",
    "        all_combined_results = pd.concat([all_combined_results, current_df.results])\n",
    "        \n",
    "        \n",
    "    for x_variable, pretty_df in zip(['booster', 'evi_markers', 'factive_verb'], [pretty_booster, pretty_evi, pretty_factive]):\n",
    "        y_variable = 'correct_top_1'\n",
    "\n",
    "        #-----------average results-----------------\n",
    "        df = all_combined_results\n",
    "        grouped = df.groupby(\"name\").mean().reset_index()\n",
    "        df = grouped.set_index(\"name\").join(meta.set_index(\"name\")).reset_index().dropna()\n",
    "        df = df.groupby([x_variable])[features].mean().reset_index().dropna()\n",
    "        display(df.round(3))\n",
    "        pretty_df = pd.concat([pretty_df, df], axis=1)\n",
    "\n",
    "        #-----------bootstrap results-----------------\n",
    "        bootstrap_results = pd.DataFrame()\n",
    "        df['x_variable'] = x_variable\n",
    "        df['model_name'] = [MODEL_NAME] * len(df)\n",
    "\n",
    "        bootstrap_df = get_bootstrap_confidence(all_raw_results, y_variable,  x_variable_map[x_variable], x_variable)\n",
    "        bootstrap_results = pd.concat([bootstrap_results, bootstrap_df])\n",
    "\n",
    "        #-----------t test-----------------\n",
    "\n",
    "        df = all_raw_results\n",
    "        df = df.set_index(\"name\").join(meta.set_index(\"name\")).reset_index()\n",
    "\n",
    "        means1 = df[df[x_variable]==x_variable_map[x_variable][0]][y_variable].values\n",
    "        means2 = df[df[x_variable]==x_variable_map[x_variable][1]][y_variable].values\n",
    "\n",
    "        a = np.array(means1)\n",
    "        b = np.array(means2)\n",
    "        print(np.array(a).mean(), np.array(b).mean())\n",
    "        print(x_variable, st.ttest_ind(a=a, b=b, equal_var=True))\n",
    "        print(\"-----------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d37ff4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pretty_booster)\n",
    "display(pretty_evi)\n",
    "display(pretty_factive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583813ed",
   "metadata": {},
   "source": [
    "# Pre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "598bf4cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Model name openai/ada\n",
      "jeopardy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.014722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.018387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster       0.014722\n",
       "1    hedge       0.018387\n",
       "2     none       0.025000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.01097 percentile .975 0.01889\n",
      "Bootstrap results percentile .025 0.01532 percentile .975 0.02145\n",
      "Booster Ttest_indResult(statistic=-1.3513765547396486, pvalue=0.17660604022379645)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.013043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker       0.020741\n",
       "1  no_evidential_marker       0.013043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.01722 percentile .975 0.02444\n",
      "Bootstrap results percentile .025 0.01 percentile .975 0.01609\n",
      "Evidential Marker Ttest_indResult(statistic=2.951623755172327, pvalue=0.0031684201718406055)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.014091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb       0.014091\n",
       "1  no_factive_verb       0.018077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.00931 percentile .975 0.01909\n",
      "Bootstrap results percentile .025 0.015 percentile .975 0.02103\n",
      "Factive Verbs Ttest_indResult(statistic=-1.2699664702276314, pvalue=0.20412612944343408)\n",
      "-----------\n",
      "----------------------\n",
      "Model name openai/babbage\n",
      "jeopardy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.040484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster       0.045000\n",
       "1    hedge       0.040484\n",
       "2     none       0.040000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.03874 percentile .975 0.05194\n",
      "Bootstrap results percentile .025 0.03548 percentile .975 0.04508\n",
      "Booster Ttest_indResult(statistic=1.0726776185934064, pvalue=0.28344220431526745)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.033261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker       0.049630\n",
       "1  no_evidential_marker       0.033261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.04389 percentile .975 0.05556\n",
      "Bootstrap results percentile .025 0.02826 percentile .975 0.03837\n",
      "Evidential Marker Ttest_indResult(statistic=4.065422432248784, pvalue=4.831286597417214e-05)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.041154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb       0.045455\n",
       "1  no_factive_verb       0.041154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.03682 percentile .975 0.05433\n",
      "Bootstrap results percentile .025 0.03667 percentile .975 0.04648\n",
      "Factive Verbs Ttest_indResult(statistic=0.8870952271536557, pvalue=0.37504897157368744)\n",
      "-----------\n",
      "----------------------\n",
      "Model name openai/curie\n",
      "jeopardy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.070833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.075161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster       0.070833\n",
       "1    hedge       0.075161\n",
       "2     none       0.105000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.06278 percentile .975 0.07974\n",
      "Bootstrap results percentile .025 0.06846 percentile .975 0.08121\n",
      "Booster Ttest_indResult(statistic=-0.7910901512319894, pvalue=0.4289105345607347)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.080556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.066739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker       0.080556\n",
       "1  no_evidential_marker       0.066739"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.07398 percentile .975 0.08759\n",
      "Bootstrap results percentile .025 0.05913 percentile .975 0.07316\n",
      "Evidential Marker Ttest_indResult(statistic=2.62795214070479, pvalue=0.008603183297636492)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.067727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.076026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb       0.067727\n",
       "1  no_factive_verb       0.076026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.05703 percentile .975 0.07955\n",
      "Bootstrap results percentile .025 0.07 percentile .975 0.08205\n",
      "Factive Verbs Ttest_indResult(statistic=-1.3115496322409408, pvalue=0.1897022536389926)\n",
      "-----------\n",
      "----------------------\n",
      "Model name openai/davinci\n",
      "jeopardy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.207222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.239839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster       0.207222\n",
       "1    hedge       0.239839\n",
       "2     none       0.380000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.19513 percentile .975 0.21972\n",
      "Bootstrap results percentile .025 0.22935 percentile .975 0.2509\n",
      "Booster Ttest_indResult(statistic=-3.71323243847771, pvalue=0.0002057642339831271)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.203889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.262609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker       0.203889\n",
       "1  no_evidential_marker       0.262609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.19323 percentile .975 0.21417\n",
      "Bootstrap results percentile .025 0.25087 percentile .975 0.27555\n",
      "Evidential Marker Ttest_indResult(statistic=-6.960868584323098, pvalue=3.5942095364444796e-12)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.170455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.247949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb       0.170455\n",
       "1  no_factive_verb       0.247949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.15636 percentile .975 0.1866\n",
      "Bootstrap results percentile .025 0.23812 percentile .975 0.25699\n",
      "Factive Verbs Ttest_indResult(statistic=-7.6391430957760145, pvalue=2.3871868038174296e-14)\n",
      "-----------\n",
      "----------------------\n",
      "Model name openai/text-davinci-003\n",
      "jeopardy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booster</td>\n",
       "      <td>0.549444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hedge</td>\n",
       "      <td>0.602581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  correct_top_1\n",
       "0  booster       0.549444\n",
       "1    hedge       0.602581\n",
       "2     none       0.560000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.53235 percentile .975 0.56431\n",
      "Bootstrap results percentile .025 0.58984 percentile .975 0.61607\n",
      "Booster Ttest_indResult(statistic=-5.14960515224819, pvalue=2.6610706833178397e-07)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evi_markers</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidential_marker</td>\n",
       "      <td>0.573704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_evidential_marker</td>\n",
       "      <td>0.593043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            evi_markers  correct_top_1\n",
       "0     evidential_marker       0.573704\n",
       "1  no_evidential_marker       0.593043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.56064 percentile .975 0.58658\n",
      "Bootstrap results percentile .025 0.57902 percentile .975 0.6062\n",
      "Evidential Marker Ttest_indResult(statistic=-1.9548133027129866, pvalue=0.050632937580972516)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factive_verb</th>\n",
       "      <th>correct_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factive_verb</td>\n",
       "      <td>0.518182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_factive_verb</td>\n",
       "      <td>0.600769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      factive_verb  correct_top_1\n",
       "0     factive_verb       0.518182\n",
       "1  no_factive_verb       0.600769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap results percentile .025 0.4977 percentile .975 0.53909\n",
      "Bootstrap results percentile .025 0.58974 percentile .975 0.61173\n",
      "Factive Verbs Ttest_indResult(statistic=-6.953689165184136, pvalue=3.781122100483271e-12)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "all_results = pd.DataFrame()\n",
    "for MODEL_NAME in [\"openai/ada\", \"openai/babbage\", \"openai/curie\", \"openai/davinci\", \"openai/text-davinci-003\"]:\n",
    "    print(\"----------------------\")\n",
    "    print(\"Model name\", MODEL_NAME)\n",
    "    \n",
    "    features = ['correct_top_1']\n",
    "    \n",
    "    for current_df in datasets[3:4]:\n",
    "        print(current_df.name)\n",
    "        meta = templates_meta_data()\n",
    "        current_df = get_results(current_df, MODEL_NAME, NUM_COMPLETIONS, MAX_TOKENS, TEMPERATURE, TOP_K_PER_TOKEN, STOP_SEQUENCES)\n",
    "\n",
    "        for y_variable in ['correct_top_1']:\n",
    "            for x_variable, title in zip(['booster', 'evi_markers', 'factive_verb'], ['Booster', \"Evidential Marker\", 'Factive Verbs']):\n",
    "\n",
    "                all_results = pd.DataFrame()\n",
    "                bootstrap_results = pd.DataFrame()\n",
    "\n",
    "                #-----------average results-----------------\n",
    "                df = current_df.results\n",
    "                grouped = df.groupby(\"name\").mean().reset_index()\n",
    "                df = grouped.set_index(\"name\").join(meta.set_index(\"name\")).reset_index().dropna()\n",
    "                df = df.groupby([x_variable])[features].mean().reset_index().dropna()\n",
    "                display(df.round(3))\n",
    "                \n",
    "                #-----------bootstrap results-----------------\n",
    "                df['dataset'] = [current_df.name_pretty] * len(df)\n",
    "                df['x_variable'] = x_variable\n",
    "                df['model_name'] = [MODEL_NAME] * len(df)\n",
    "                \n",
    "                bootstrap_df = get_bootstrap_confidence(current_df.raw_results, y_variable,  x_variable_map[x_variable], x_variable)\n",
    "                bootstrap_df['dataset'] = [current_df.name_pretty] * len(bootstrap_df)\n",
    "                bootstrap_results = pd.concat([bootstrap_results, bootstrap_df])\n",
    "                \n",
    "                #-----------t test-----------------\n",
    "                \n",
    "                df = current_df.raw_results\n",
    "                df = df.set_index(\"name\").join(meta.set_index(\"name\")).reset_index()\n",
    "\n",
    "                means1 = df[df[x_variable]==x_variable_map[x_variable][0]][y_variable].values\n",
    "                means2 = df[df[x_variable]==x_variable_map[x_variable][1]][y_variable].values\n",
    "\n",
    "                a = np.array(means1)\n",
    "                b = np.array(means2)\n",
    "\n",
    "                print(title, st.ttest_ind(a=a, b=b, equal_var=True))\n",
    "                print(\"-----------\")\n",
    "                all_results = pd.concat([all_results, df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c2646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
